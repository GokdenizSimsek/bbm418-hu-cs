# -*- coding: utf-8 -*-
"""BBM418-assignment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jrSpzUfTjCC7DD8hu5jcvz_8sBqnhBjK
"""

from google.colab import drive
drive.mount('/content/drive')

import shutil
shutil.copytree("/content/drive/MyDrive/WarpDoc", "/content/WarpDoc")

import cv2
import numpy as np
import itertools
from scipy.spatial import distance
import matplotlib.pyplot as plt
from skimage.metrics import structural_similarity as ssim

def fast_hough_transform(edges, rho=1, theta_step=np.pi/180, threshold=100):
    # Get coordinates of edge pixels
    y, x = np.where(edges > 0)

    # Hough Space parameters
    diag = int(np.ceil(np.sqrt(edges.shape[0]**2 + edges.shape[1]**2)))
    thetas = np.arange(0, np.pi, theta_step)
    cos_t = np.cos(thetas)
    sin_t = np.sin(thetas)
    num_thetas = len(thetas)

    # Hough Accumulator (rho values ​​from -diag to +diag)
    accumulator = np.zeros((2 * diag, num_thetas), dtype=np.uint64)
    rhos = np.linspace(-diag, diag, 2 * diag)

    # Vectorized voting (optimized with NumPy)
    r_values = x[:, None] * cos_t + y[:, None] * sin_t  # r for all (x,y) and thetas
    r_indices = np.round((r_values + diag) / (2 * diag) * (2 * diag - 1)).astype(int)

    # Count votes for each (theta_idx, r_idx) pair
    for theta_idx in range(num_thetas):
        np.add.at(accumulator[:, theta_idx], r_indices[:, theta_idx], 1)

    # Find lines on Threshold
    lines = []
    for r_idx in range(accumulator.shape[0]):
        for theta_idx in range(accumulator.shape[1]):
            if (accumulator[r_idx, theta_idx] > threshold):
                rho_val = rhos[r_idx]
                theta_val = thetas[theta_idx]
                lines.append((rho_val, theta_val, accumulator[r_idx, theta_idx]))

    return lines

def compute_perspective_matrix(src_pts, dst_pts):

    """
    Calculates a 4-point perspective transformation matrix.
    """
    A = []
    for i in range(4):
        x, y = src_pts[i]
        u, v = dst_pts[i]
        A.append([x, y, 1, 0, 0, 0, -u*x, -u*y, -u])
        A.append([0, 0, 0, x, y, 1, -v*x, -v*y, -v])

    A = np.array(A, dtype=np.float32)
    _, _, V = np.linalg.svd(A)  # Singular Value Decomposition
    H = V[-1].reshape(3, 3)  # Last row is the solution matrix

    return H / H[2, 2]  # Normalize the matrix by setting the last element to 1

def apply_perspective_transform(image, H, width, height):
    """
    Applies perspective transformation.
    """
    inv_H = np.linalg.inv(H)  # Inverse matrix
    output = np.zeros((height, width, 3), dtype=np.uint8)

    for y in range(height):
        for x in range(width):
            # Transform the point (x, y) in the new image to the old image
            vec = np.array([x, y, 1])
            new_coords = inv_H @ vec
            new_coords /= new_coords[2]  # Normalize homogeneous coordinates

            orig_x, orig_y = int(new_coords[0]), int(new_coords[1])

            # Move pixels if they are within the old image borders
            if 0 <= orig_x < image.shape[1] and 0 <= orig_y < image.shape[0]:
                output[y, x] = image[orig_y, orig_x]

    return output

def find_intersections(lines, angle_threshold=np.pi/36):  # 5 degrees (~0.087 rad) threshold
    intersections = []
    for (rho1, theta1, _), (rho2, theta2, _) in itertools.combinations(lines, 2):
        # If the angle difference is very small, the lines are almost parallel, skip
        if abs(theta1 - theta2) < angle_threshold:
            continue

        A = np.array([[np.cos(theta1), np.sin(theta1)],
                      [np.cos(theta2), np.sin(theta2)]])
        b = np.array([[rho1], [rho2]])
        if np.linalg.det(A) != 0:  # If the determinant is not zero (if the lines are not exactly parallel)
            xy = np.linalg.solve(A, b)
            intersections.append((int(xy[0][0]), int(xy[1][0])))
    return intersections

def filter_points_inside_image(points, width, height):
    return [(x, y) for x, y in points if 0 <= x < width and 0 <= y < height]

def find_largest_quadrilateral(points, min_points=10):
    if len(points) < min_points:
        print(f"Warning: Insufficient number of points: ({len(points)}). At least {min_points} is required.")
        return None

    try:
        # Convert points to appropriate format
        points_np = np.array(points, dtype=np.float32)

        # Filter singular points
        unique_points = np.unique(points_np, axis=0)
        if len(unique_points) < 3:
            print("Warning: Insufficient number of unique points.")
            return None

        # Find the convex hull
        hull = cv2.convexHull(unique_points)

        # If there are 4 corners, return directly
        if len(hull) == 4:
            return hull.reshape(4, 2)

        # Search for the best quadrilateral (RANSAC-like approach)
        max_area = 0
        best_quad = None
        for _ in range(100):  # 100 times
            sample = cv2.convexHull(unique_points[np.random.choice(len(unique_points), 4, replace=False)])
            if len(sample) == 4:
                area = cv2.contourArea(sample)
                if area > max_area:
                    max_area = area
                    best_quad = sample.reshape(4, 2)

        return best_quad

    except Exception as e:
        print(f"Error: convexHull operation failed - {str(e)}")
        return None

# to validates the vertices and puts them in standard order
def validate_and_order_corners(corners, image_shape):
    if len(corners) != 4:
        raise ValueError("Tam olarak 4 köşe noktası gereklidir")

    # Check image boundaries
    h, w = image_shape[:2]
    corners = np.array([(max(0, min(x, w-1)), max(0, min(y, h-1))) for (x,y) in corners])

    # Angular sorting by center point
    center = np.mean(corners, axis=0)
    angles = np.arctan2(corners[:,1]-center[1], corners[:,0]-center[0])
    return corners[np.argsort(angles)]

def robust_perspective_warp(image, corners):
    # Validate and sort the vertices
    ordered_corners = validate_and_order_corners(corners, image.shape)

    # Calculate target dimensions (keep original aspect ratio)
    (tl, tr, br, bl) = ordered_corners
    width = max(int(np.linalg.norm(tr - tl)), int(np.linalg.norm(br - bl)))
    height = max(int(np.linalg.norm(bl - tl)), int(np.linalg.norm(br - tr)))

    # Target points (top left, top right, bottom right, bottom left)
    dst = np.array([
        [0, 0],
        [width - 1, 0],
        [width - 1, height - 1],
        [0, height - 1]], dtype="float32")

    # Transformation matrix
    M = compute_perspective_matrix(ordered_corners.astype(np.float32), dst)

    # apply perspective correction
    warped = apply_perspective_transform(image, M, width, height)

    return warped

def full_processing_pipeline(image_path, digital_image_path, blur1, blur2, blur3, canny1, canny2, threshold): # changeable and required parameters

    # 1. Image loading and preprocessing
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    resized = cv2.resize(image, (1024, 1024))

    original_image = cv2.imread(digital_image_path)
    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
    resized_original = cv2.resize(original_image, (1024, 1024))

    gray = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY)
    blurred = cv2.GaussianBlur(gray, (blur1, blur2), blur3)
    edges = cv2.Canny(blurred, canny1, canny2)

    # 2. Find lines with Hough Transform
    lines = fast_hough_transform(edges, threshold)

    # 3. Find and filter intersection points
    intersections = find_intersections(lines)
    valid_points = filter_points_inside_image(intersections, 1024, 1024)

    # 4. Find the largest quadrilateral
    quad = find_largest_quadrilateral(valid_points)

    if quad is not None:
        # 5. Perspective correction
        try:
            warped = robust_perspective_warp(resized, quad)
            warped = cv2.resize(warped, (1024, 1024))

            warped_gray = cv2.cvtColor(warped, cv2.COLOR_RGB2GRAY)
            original_gray = cv2.cvtColor(resized_original, cv2.COLOR_RGB2GRAY)

            ssim_score = ssim(warped_gray, original_gray)

            # Show and compare results
            plt.figure(figsize=(20, 6))

            plt.subplot(1, 3, 1)
            plt.imshow(resized)
            plt.title("Given Image")

            plt.subplot(1, 3, 2)
            plt.imshow(warped)
            plt.title("Found Image")

            plt.subplot(1, 3, 3)
            plt.imshow(resized_original)
            plt.title("Target Image")
            plt.show()


            return ssim_score
        except Exception as e:
            print(f"An error occurred: {str(e)}")
            return None
    else:
        print("No valid rectangle found!")
        return None

print("\n\n*********************************** ROTATE ***********************************\n\n")
rotate_ssim_total = 0
# for rotate class
for i in range(50):
    if i < 10:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/rotate/000" + str(i) + ".jpg", "/content/WarpDoc/digital/rotate/000" + str(i) + ".jpg", 11, 11, 2, 50, 270, 100)
    else:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/rotate/00" + str(i) + ".jpg", "/content/WarpDoc/digital/rotate/00" + str(i) + ".jpg", 11, 11, 2, 50, 270, 100)
    if ssim_value is not None:
        rotate_ssim_total += ssim_value
        print(f"SSIM value: {ssim_value}")
    else:
        print("SSIM value: 0")
print(f"SSIM Mean for ROTATE class is: {rotate_ssim_total/50}")

print("\n\n*********************************** RANDOM ***********************************\n\n")
random_ssim_total = 0
# for random class
for i in range(50):
    if i < 10:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/random/000" + str(i) + ".jpg", "/content/WarpDoc/digital/random/000" + str(i) + ".jpg", 11, 11, 2, 50, 200, 105)
    else:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/random/00" + str(i) + ".jpg", "/content/WarpDoc/digital/random/00" + str(i) + ".jpg", 11, 11, 2, 50, 200, 105)
    if ssim_value is not None:
        random_ssim_total += ssim_value
        print(f"SSIM value: {ssim_value}")
    else:
        print("SSIM value: 0")
print(f"SSIM Mean for RANDOM class is: {random_ssim_total/50}")

print("\n\n*********************************** FOLD ***********************************\n\n")
fold_ssim_total = 0
# for fold class
for i in range(50):
    if i < 10:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/fold/000" + str(i) + ".jpg", "/content/WarpDoc/digital/fold/000" + str(i) + ".jpg", 11, 11, 2, 50, 200, 100)
    else:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/fold/00" + str(i) + ".jpg", "/content/WarpDoc/digital/fold/00" + str(i) + ".jpg", 11, 11, 2, 50, 200, 100)
    if ssim_value is not None:
        fold_ssim_total += ssim_value
        print(f"SSIM value: {ssim_value}")
    else:
        print("SSIM value: 0")
print(f"SSIM Mean for FOLD class is: {fold_ssim_total/50}")

print("\n\n*********************************** INCOMPLETE ***********************************\n\n")
incomplete_ssim_total = 0
# for incomplete class
for i in range(50):
    if i < 10:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/incomplete/000" + str(i) + ".jpg", "/content/WarpDoc/digital/incomplete/000" + str(i) + ".jpg", 11, 11, 2, 50, 270, 120)
    else:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/incomplete/00" + str(i) + ".jpg", "/content/WarpDoc/digital/incomplete/00" + str(i) + ".jpg", 11, 11, 2, 50, 270, 120)
    if ssim_value is not None:
        incomplete_ssim_total += ssim_value
        print(f"SSIM value: {ssim_value}")
    else:
        print("SSIM value: 0")
print(f"SSIM Mean for INCOMPLETE class is: {incomplete_ssim_total/50}")

print("\n\n*********************************** CURVED ***********************************\n\n")
curved_ssim_total = 0
# for curved class
for i in range(50):
    if i < 10:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/curved/000" + str(i) + ".jpg", "/content/WarpDoc/digital/curved/000" + str(i) + ".jpg", 11, 11, 2, 50, 200, 100)
    else:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/curved/00" + str(i) + ".jpg", "/content/WarpDoc/digital/curved/00" + str(i) + ".jpg", 11, 11, 2, 50, 200, 100)
    if ssim_value is not None:
        curved_ssim_total += ssim_value
        print(f"SSIM value: {ssim_value}")
    else:
        print("SSIM value: 0")
print(f"SSIM Mean for CURVED class is: {curved_ssim_total/50}")

print("\n\n*********************************** PERSPECTIVE ***********************************\n\n")
perspective_ssim_total = 0
# for perspective class
for i in range(50):
    if i < 10:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/perspective/000" + str(i) + ".jpg", "/content/WarpDoc/digital/perspective/000" + str(i) + ".jpg", 11, 11, 2, 50, 270, 120)
    else:
        ssim_value = full_processing_pipeline("/content/WarpDoc/distorted/perspective/00" + str(i) + ".jpg", "/content/WarpDoc/digital/perspective/00" + str(i) + ".jpg", 11, 11, 2, 50, 270, 120)
    if ssim_value is not None:
        perspective_ssim_total += ssim_value
        print(f"SSIM value: {ssim_value}")
    else:
        print("SSIM value: 0")
print(f"SSIM Mean for PERSPECTIVE class is: {perspective_ssim_total/50}")